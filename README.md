# Movies-ETL

## Resources
Data Used: movies_metadata.csv, ratings.csv, wikipedia-movies.json
Images: movies_query.png, ratings_query.png
Software: Python 3.9, GitHub Desktop 2.8.3, VS Code 1.56, Juypter Notebook

## Overview

Amazing Prime ask for my help to create an automated pipeline that takes in new data, performs the appropriate transformations, and loads the data into existing tables. I’ll need to refactor the code to create one function that takes in the three files—Wikipedia data, Kaggle metadata, and the MovieLens rating data—and performs the ETL process by adding the data to a PostgreSQL database.


## Objectives

Deliverable 1: Write an ETL Function to Read Three Data Files  - ETL_function_test.ipynb

Deliverable 2: Extract and Transform the Wikipedia Data - ETL_clean_wiki_movies.ipynb

Deliverable 3: Extract and Transform the Kaggle Data - ETL_clean_kaggle_data.ipynb

Deliverable 4: Create the Movie Database - ETL_create_database.ipynb, movies_query.png, ratings_query.png



 
